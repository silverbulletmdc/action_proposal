import pickle
import os
import time
import multiprocessing as mp
from typing import Tuple, Dict
import argparse
import pandas as pd
import numpy as np
from scipy.interpolate import interp1d
from action_proposals.dataset import VideoRecordHandler, VideoRecord, ActivityNetDataset
from action_proposals.utils import load_yml, mkdir_p,log


class PgmFeatureHandler(VideoRecordHandler):
    def __init__(self, tem_csv_dir: str, proposal_csv_path: str, subset: str = "training"):
        r"""
        PGM feature handler.

        :param tem_results_file: result file path of TEM generated by tem_test.
        :param proposal_csv_path: result file path of proposal generated by pgm proposal generation.
        :param subset: "training", "validation"
        """
        self._tem_csv_dir = tem_csv_dir
        self._proposal_csv_path = proposal_csv_path

    def __call__(self, video_record: VideoRecord) -> Tuple[np.ndarray, VideoRecord, np.ndarray]:
        """

        :param video_record:
        :return: scores [L, 3] (start, actionness, end),
                 video record,
                 proposals [N, 6] (xmin, xmax, min_score, max_score, iou, ioa)
        """
        proposals_path = os.path.join(self._proposal_csv_path, '{}.csv'.format(video_record.video_name))
        proposals = pd.read_csv(proposals_path)

        tem_features_path = os.path.join(self._tem_csv_dir, '{}.csv'.format(video_record.video_name))
        feature_df = pd.read_csv(tem_features_path)
        features = np.array([feature_df.start, feature_df.action, feature_df.end]).T
        return features, video_record, proposals.values


def get_pgm_feature_dataset(tem_csv_dir: str, proposal_csv_path: str, json_path: str, video_info_new_csv_path: str,
                            subset: str):
    video_record_handler = PgmFeatureHandler(tem_csv_dir, proposal_csv_path, subset)
    return ActivityNetDataset(json_path=json_path, video_info_new_csv_path=video_info_new_csv_path,
                              video_record_handler=video_record_handler, subset=subset)


def generate_feature(scores: np.ndarray, video_record: VideoRecord, proposals: np.ndarray, subset: str) -> np.ndarray:
    """
    Generate BSP features.

    :param scores: [L, 3] (start, actionness, end),
    :param video_record: video info
    :param proposals:  [N, 6] (xmin, xmax, min_score, max_score, iou, ioa)
    :param subset: training or validation

    :return: [N, 32] Concatenate features.
    """
    num_sample_start = 8
    num_sample_end = 8
    num_sample_action = 16
    num_sample_interp1d = 3

    _, score_action, _ = scores.T
    tscale = scores.shape[0]
    tgap = 1.0 / tscale
    seg_xmins = np.array([tgap * i for i in range(tscale)])
    seg_xmaxs = np.array([tgap * i for i in range(1, tscale + 1)])

    video_scale = tscale
    video_gap = tgap
    video_extend = video_scale // 4 + 10

    if subset == "training":
        proposals = proposals[:500]
    else:
        proposals = proposals[:1000]

    tmp_zeros = np.zeros([video_extend])
    score_action = np.concatenate([tmp_zeros, score_action, tmp_zeros])
    tmp_cell = video_gap
    tmp_x = [-tmp_cell / 2 - (video_extend - 1 - i) * tmp_cell for i in range(video_extend)] + \
            [tmp_cell / 2 + i * tmp_cell for i in range(video_scale)] + \
            [tmp_cell / 2 + seg_xmaxs[-1] + i * tmp_cell for i in range(video_extend)]
    f_action = interp1d(tmp_x, score_action, axis=0)
    feature_bsp = []

    xmin = proposals[:, 0]
    xmax = proposals[:, 1]
    xlen = xmax - xmin
    xmin_0 = xmin - xlen / 5
    xmin_1 = xmin + xlen / 5
    xmax_0 = xmax - xlen / 5
    xmax_1 = xmax + xlen / 5

    # 插值得到结果。将每个点周围三等分，取4个点。再对4个点取均值

    # start
    plen_start = (xmin_1 - xmin_0) / (num_sample_start - 1)
    plen_sample = plen_start / num_sample_interp1d
    tmp_x_new = [xmin_0 - plen_start / 2 + plen_sample * i for i in
                 range(num_sample_start * num_sample_interp1d + 1)]
    tmp_y_new_start_action = f_action(tmp_x_new)
    tmp_y_new_start = [
        np.mean(tmp_y_new_start_action[ii * num_sample_interp1d:(ii + 1) * num_sample_interp1d + 1], axis=0)
        for ii in range(num_sample_start)
    ]

    # end
    plen_end = (xmax_1 - xmax_0) / (num_sample_end - 1)
    plen_sample = plen_end / num_sample_interp1d
    tmp_x_new = [xmax_0 - plen_end / 2 + plen_sample * i for i in
                 range(num_sample_end * num_sample_interp1d + 1)]
    tmp_y_new_end_action = f_action(tmp_x_new)
    tmp_y_new_end = [
        np.mean(tmp_y_new_end_action[ii * num_sample_interp1d:(ii + 1) * num_sample_interp1d + 1], axis=0)
        for ii in range(num_sample_end)
    ]

    # action
    plen_action = (xmax - xmin) / (num_sample_action - 1)
    plen_sample = plen_action / num_sample_interp1d
    tmp_x_new = [xmin - plen_action / 2 + plen_sample * ii for ii in
                 range(num_sample_action * num_sample_interp1d + 1)]
    tmp_y_new_action = f_action(tmp_x_new)
    tmp_y_new_action = [np.mean(tmp_y_new_action[ii * num_sample_interp1d:(ii + 1) * num_sample_interp1d + 1], axis=0)
                        for ii in range(num_sample_action)]

    tmp_feature = np.concatenate([tmp_y_new_action, tmp_y_new_start, tmp_y_new_end]).T
    # feature_bsp.append(tmp_feature)
    # feature_bsp = np.array(feature_bsp)
    return tmp_feature


def proc_cb(q: mp.Queue, cfg: argparse.Namespace, datasets):
    """

    :param q: A queue of (subset: str, idx: int).
    :param cfg: config.
    :param datasets: A dict of "training": train_dataset and "validation": val_dataset
    :return:
    """
    while True:
        subset, idx = q.get()
        scores, video_record, proposals = datasets[subset][idx]
        bsp_features = generate_feature(scores, video_record, proposals, subset)
        np.save(os.path.join(cfg.pgm.pgm_feature_path, video_record.video_name), bsp_features)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--yml_cfg_file", type=str, default="./cfgs/bsn.yml")
    args = parser.parse_args()
    cfg = load_yml(args.yml_cfg_file)

    anet = cfg.anet
    train_dataset = get_pgm_feature_dataset(cfg.tem.tem_csv_dir, cfg.pgm.proposal_csv_path, anet.json_path,
                                            anet.video_info_new_csv_path, "training")
    val_dataset = get_pgm_feature_dataset(cfg.tem.tem_csv_dir, cfg.pgm.proposal_csv_path, anet.json_path,
                                          anet.video_info_new_csv_path, "validation")

    queue = mp.Queue()
    procs = []

    mkdir_p(cfg.pgm.pgm_feature_path)
    for i in range(len(train_dataset)):
        queue.put(('training', i))

    for i in range(len(val_dataset)):
        queue.put(('validation', i))

    for i in range(cfg.pgm.pgm_feature_workers):
        proc = mp.Process(target=proc_cb, args=(queue, cfg, {"training": train_dataset, "validation": val_dataset}))
        procs.append(proc)
        proc.start()

    t = 0
    while not queue.empty():
        log.log_info('{}s: Remain {} videos to be handled.'.format(t, queue.qsize()))
        time.sleep(1)
        t += 1
    log.log_warn("All video processed.")
    for proc in procs:
        proc.terminate()


if __name__ == '__main__':
    main()
